# Time Series Forecasting Project: An In-depth Exploration

This project documents a comprehensive journey into time series forecasting, evolving from a simple model comparison into a deep investigation of the critical relationship between feature engineering and model architecture. Our central achievement is the development of **T-LAFS (Time-series LLM-driven Adaptive Feature Synthesis)**, a sophisticated framework that uses a Large Language Model to autonomously devise and test feature engineering strategies.

## Final Conclusion: The "Feature-Model Mismatch" Hypothesis Confirmed

After an extensive and iterative process, our work culminated in a final, all-encompassing experiment. We tasked our fully evolved T-LAFS framework to autonomously generate a set of features from the raw time series data. This AI-generated feature set was then tested against a diverse lineup of models. The results were dramatic, conclusive, and provided the ultimate answer to our core research question.

### The Final Scoreboard

| Model                     | RÂ² Score | Analysis                                                                                                 |
| ------------------------- | :------: | -------------------------------------------------------------------------------------------------------- |
| **RandomForest**          | **0.8446** | **The Undisputed Champion**. Perfectly capitalized on the rich, complex features generated by T-LAFS.        |
| **XGBoost**               | **0.7034** | **Excellent Performer**. Also benefited immensely from the comprehensive feature set.                        |
| **LightGBM**              | **0.6448** | **Solid and Reliable**. Served as the baseline evaluator during T-LAFS's search, showing consistent results. |
| **SimpleNN (MLP)**        | -0.1089  | **Complete Failure**. The pre-processed features severely hindered its ability to learn.                   |
| **EnhancedNN (LSTM+Attn)**| -0.0679  | **Also Failed**. Completely lost in the sea of engineered features, unable to leverage its sequential power. |

### Key Insights

1.  **Features are King, but They Serve a Specific Master**: T-LAFS proved that automated, strategic feature engineering is the key to unlocking significant predictive power. The success of the tree-based models is a direct result of the rich, high-dimensional feature space created by the AI.

2.  **The "Feature-Model Mismatch" Hypothesis is Unequivocally Proven**: This final scoreboard provides undeniable evidence for our central theory.
    *   **For Tree-Based Models**: The engineered features were a gourmet meal. These models excel at navigating high-dimensional spaces and making decisions based on the most informative features, effectively leveraging the "all-you-can-eat buffet" of features we provided.
    *   **For Neural Networks**: The same features were poison. By feeding them pre-digested, high-level information (like rolling averages and lags), we severely interfered with their innate ability to learn deeper, more abstract patterns from the data. The LSTM, which should have excelled, was misled by these explicit and highly correlated features, resulting in a catastrophic performance.

3.  **There is No "Best Model," Only the Right Combination**: This project is a textbook case study demonstrating that the most powerful model architecture can fail spectacularly if paired with an inappropriate feature engineering strategy. Success lies not in finding the strongest individual components, but in creating the most synergistic combination.

## The Journey

Our collaboration was a multi-stage exploration, marked by critical discoveries and iterative development:

1.  **Initial Anomaly & The "Data Leakage" Discovery**: We began by questioning why a `SimpleNN` was outperforming a more complex `EnhancedNN` (LSTM+Attention). This led to a crucial discovery: the original feature engineering process was inadvertently **leaking future information** into the training data, creating artificially inflated and misleading scores.

2.  **The Rise of T-LAFS**: To systematically explore feature engineering, we created T-LAFS. Its first version selected features one by one, but quickly hit a performance plateau, revealing the limitations of a "greedy" approach.

3.  **Evolution into a Strategist**: The breakthrough came when we "upgraded" T-LAFS from a mere feature selector into a **Feature Engineering Strategist**. We re-wrote its core prompt to encourage the LLM to devise and test *combinations* of diverse features (e.g., a lag, a trend, and a seasonality feature together).

4.  **The Grand Finale**: This final, evolved version of T-LAFS autonomously generated the high-quality feature set that produced the conclusive results above, validating our journey and solidifying our insights.

## How to Run the Final Experiment

The culmination of our work is encapsulated in the `t_lafs_demo.py` script.

### Prerequisites

1.  **Environment**: Ensure you have Python 3.8+ and the required packages installed:
    ```bash
    pip install -r requirements.txt
    ```

2.  **OpenAI API Key**: This script requires an OpenAI-compatible API key. Set it as an environment variable:
    ```bash
    # On Windows (Command Prompt)
    set OPENAI_API_KEY=your_api_key_here

    # On Windows (PowerShell)
    $env:OPENAI_API_KEY="your_api_key_here"

    # On macOS/Linux
    export OPENAI_API_KEY=your_api_key_here
    ```
    You may also need to set `OPENAI_BASE_URL` if you are using a proxy or a different service endpoint.

### Execution

To run the full demonstration, which includes autonomous feature generation by the LLM followed by a final evaluation on all five models, simply execute the script:

```bash
python t_lafs_demo.py
```

The script will:
1.  Initialize the T-LAFS algorithm with raw data.
2.  Iteratively use the LLM to propose and evaluate feature *combinations* for 5 rounds.
3.  Apply the best feature set discovered by T-LAFS.
4.  Train and evaluate five different models (LightGBM, RandomForest, XGBoost, SimpleNN, EnhancedNN) on this AI-generated feature set.
5.  Print a final report comparing the performance of all models. 